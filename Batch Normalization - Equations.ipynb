{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Math,Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch normalization is defined as transformation of input $\\hat{x}$ having standard distribution with zero mean and unit variance to $y^k$, given as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "y^k = \\gamma^k\\hat{x}^k + \\beta^k\n",
    "\\end{equation}\n",
    "\n",
    "where, $x$ is $d$-dimensional input = ($x^1$,$x^2$,...,$x^d$). $\\gamma$ and $\\beta$ are $d$-dimensional parameters learned during training. Using the equation above we get the following equation in matrix notation:\n",
    "\n",
    "$$\\begin{bmatrix}y_0^0&&y_0^1&&y_0^2&&..&&..&&y_0^d\\\\y_1^0&&y_1^1&&y_1^2&&..&&..&&y_1^d\\\\..&&..&&..&&..&&..&&..\\\\..&&..&&..&&..&&..&&..\\\\y_N^0&&y_N^1&&y_N^2&&..&&..&&y_N^d \\end{bmatrix} = \\begin{bmatrix}\\gamma^0x_0^0+\\beta^0&&\\gamma^1x_0^1+\\beta^1&&\\gamma^2x_0^2+\\beta^2&&..&&..&&\\gamma^dx_0^d+\\beta^d\\\\\\gamma^0x_1^0+\\beta^0&&\\gamma^1x_1^1+\\beta^1&&\\gamma^2x_1^2+\\beta^2&&..&&..&&\\gamma^dx_1^d+\\beta^d\\\\..&&..&&..&&..&&..&&..\\\\..&&..&&..&&..&&..&&..\\\\\\gamma^0x_N^0+\\beta^0&&\\gamma^1x_N^1+\\beta^1&&\\gamma^2x_N^2+\\beta^2&&..&&..&&\\gamma^dx_N^d+\\beta^d \\end{bmatrix}$$ \n",
    "\n",
    "However, I am not very sure whether the matrix equation falls in line with its intended form. The reason for my apprehension is that obtaining the above matrix form of equation is not possible as is because for that to happen either the equation has to be written with $\\boldsymbol{X}$ and $\\boldsymbol{Y}$ in their transpose form as follows:\n",
    "\n",
    "$$\\begin{bmatrix}y_0^0&&y_1^0&&y_2^0&&..&&..&&y_N^0\\\\y_0^1&&y_1^1&&y_2^1&&..&&..&&y_N^1\\\\..&&..&&..&&..&&..&&..\\\\..&&..&&..&&..&&..&&..\\\\y_0^d&&y_1^d&&y_2^d&&..&&..&&y_N^d \\end{bmatrix} = \\begin{bmatrix}\\gamma^0x_0^0+\\beta^0&&\\gamma^0x_1^0+\\beta^0&&\\gamma^0x_2^0+\\beta^0&&..&&..&&\\gamma^0x_N^0+\\beta^0\\\\\\gamma^1x_0^1+\\beta^1&&\\gamma^1x_1^1+\\beta^1&&\\gamma^1x_2^1+\\beta^1&&..&&..&&\\gamma^1x_N^1+\\beta^1\\\\..&&..&&..&&..&&..&&..\\\\..&&..&&..&&..&&..&&..\\\\\\gamma^dx_0^d+\\beta^d&&\\gamma^dx_1^d+\\beta^d&&\\gamma^dx_2^d+\\beta^d&&..&&..&&\\gamma^dx_N^d+\\beta^d \\end{bmatrix}$$ \n",
    "\n",
    "which can then be further decomposed as follows:\n",
    "\n",
    "$$\\begin{bmatrix}y_0&&y_1&&..&&..&&y_N\\end{bmatrix} = \\begin{bmatrix}\\gamma^0\\\\\\gamma^1\\\\..\\\\..\\\\\\gamma^d\\end{bmatrix}\n",
    "\\begin{bmatrix} x_0^0&&x_1^0&&..&&..&&x_N^0\\\\x_0^1&&x_1^1&&..&&..&&x_N^1\\\\..&&..&&..&&..&&..\\\\..&&..&&..&&..&&..\\\\x_0^d&&x_1^d&&..&&..&&x_N^d\\\\\\end{bmatrix} + \\begin{bmatrix}\\beta^0\\\\\\beta^1\\\\..\\\\..\\\\\\beta^d \\end{bmatrix}$$\n",
    "\n",
    "This decomposition should constitutes the forward pass of the batch normalization algorithm.\n",
    "\n",
    "## Backward pass in Batch Normalization\n",
    "For the Loss function $L$, we have the backward gradient w.r.t $\\boldsymbol{Y}$ as $\\frac{\\partial L}{\\partial Y}$. The gradient $\\frac{\\partial L}{\\partial \\boldsymbol{\\gamma}}$ can then be written as follows:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial \\boldsymbol{\\gamma}} = \\frac{\\partial L}{\\partial Y}.\\frac{\\partial Y}{\\partial \\gamma}$$\n",
    "\n",
    "We know that $Y$ is $N \\times D$-dimensional output and so should $\\frac{\\partial L}{\\partial Y}$ be. \n",
    "\n",
    "### <font color='red'>Here is where I start losing the grasp of things.</font>\n",
    "Using the decomposed equation above, I obtained $\\frac{\\partial Y}{\\partial \\gamma}$ as follows :\n",
    "\n",
    "$$\\frac{\\partial Y}{\\partial \\gamma} = \\begin{bmatrix}\\frac{\\partial Y_0}{\\partial \\gamma_0}&&\\frac{\\partial Y_1}{\\partial \\gamma_0}&&..&&..&&\\frac{\\partial Y_N}{\\partial \\gamma_0}\\\\\\frac{\\partial Y_0}{\\partial \\gamma_1}&&\\frac{\\partial Y_1}{\\partial \\gamma_1}&&..&&..&&\\frac{\\partial Y_N}{\\partial \\gamma_1}\\\\..&&..&&..&&..&&..\\\\..&&..&&..&&..&&..\\\\\\frac{\\partial Y_0}{\\partial \\gamma_d}&&\\frac{\\partial Y_1}{\\partial \\gamma_d}&&..&&..&&\\frac{\\partial Y_N}{\\partial \\gamma_d}\\end{bmatrix} = \\begin{bmatrix}\\hat{x}_0&&\\hat{x}_1&&..&&..&&\\hat{x}_N\\end{bmatrix}$$\n",
    "\n",
    "\n",
    "<b>Thus, $\\frac{\\partial L}{\\partial \\gamma}$ can then be written as</b>:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial \\gamma} = \\begin{bmatrix}\\frac{\\partial L}{\\partial Y_{00}}&&\\frac{\\partial L}{\\partial Y_{01}}&&..&&..&&\\frac{\\partial L}{\\partial Y_{0d}}\\\\\\frac{\\partial L}{\\partial Y_{10}}&&\\frac{\\partial L}{\\partial Y_{11}}&&..&&..&&\\frac{\\partial L}{\\partial Y_{1d}}\\\\..&&..&&..&&..&&..\\\\..&&..&&..&&..&&..\\\\\\frac{\\partial L}{\\partial Y_{N0}}&&\\frac{\\partial L}{\\partial Y_{N1}}&&..&&..&&\\frac{\\partial L}{\\partial Y_{Nd}}\\end{bmatrix} * \\begin{bmatrix}\\hat{x}_0&&\\hat{x}_1&&..&&..&&\\hat{x}_N\\end{bmatrix} = \n",
    "\\begin{bmatrix}\\frac{\\partial L}{\\partial Y_0}\\\\\\frac{\\partial L}{\\partial Y_1}\\\\..\\\\..\\\\\\frac{\\partial L}{\\partial Y_N}\\end{bmatrix}*\\begin{bmatrix}\\hat{x}_0&&\\hat{x}_1&&..&&..&&\\hat{x}_N\\end{bmatrix}$$\n",
    "\n",
    "On obtaining the above equation, one thing I understood was that this no where matches the equation given in the paper, where\n",
    "$$ \\frac{\\partial L}{\\partial \\gamma} = \\sum_{i=1}^{N} \\frac{\\partial L}{\\partial y_i}.\\hat{x}_i $$\n",
    "because, taking the <b> dot product </b> in no case results in a vector of shape $\\boldsymbol{(D,)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
